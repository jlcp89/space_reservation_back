name: Backend CI & Deploy

on:
  push:
    branches: [ main, master ]
    paths:
      - 'test1/**'
      - '.github/workflows/deploy-backend.yml'
  workflow_dispatch:
    inputs:
      reason:
        description: 'Why trigger the deploy?'
        required: false
        default: 'manual'

concurrency:
  group: backend-deploy
  cancel-in-progress: false

env:
  IMAGE_NAME: backend-api
  IMAGE_REGISTRY: ghcr.io
  CONTAINER_NAME: workspace-api
  DB_CONTAINER_NAME: workspace-db
  HOST_PORT: 3001
  CONTAINER_PORT: 3000
  DB_PORT: 5434

permissions:
  contents: read
  packages: write
  id-token: write

jobs:
  build-test-pushh:
    name: Build, Test & Push Image
    runs-on: ubuntu-latest
    outputs:
      image-tag: ${{ steps.meta.outputs.version }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Derive image meta
        id: meta
        run: |
          SHA_TAG=${GITHUB_SHA::12}
          echo "version=${SHA_TAG}" >> "$GITHUB_OUTPUT"
          echo "Image tag: ${SHA_TAG}"

      - name: Determine working directory
        id: workdir
        run: |
          if [ -f test1/package.json ]; then
            echo "Detected nested test1 project"
            echo "dir=test1" >> $GITHUB_OUTPUT
          elif [ -f package.json ]; then
            echo "Detected project at repository root"
            echo "dir=." >> $GITHUB_OUTPUT
          else
            echo "ERROR: No package.json found at root or in test1/" >&2
            ls -1
            exit 1
          fi
          echo "Using working directory: $(grep '^dir=' $GITHUB_OUTPUT | cut -d= -f2)"

      - name: Verify lockfile path
        run: |
          echo "Verifying existence of dependency lock file before setup-node cache step"
          if [ -f package-lock.json ]; then
            echo "Found lockfile at root:"; ls -l package-lock.json; FOUND=1; fi
          if [ -f test1/package-lock.json ]; then
            echo "Found lockfile in test1/:"; ls -l test1/package-lock.json; FOUND=1; fi
          if [ -z "$FOUND" ]; then
            echo "ERROR: No package-lock.json found at root or in test1/." >&2
            echo "Repository tree (top 100 lines):" >&2
            ls -R | head -100
            exit 1
          fi

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 22
          cache: npm
          cache-dependency-path: |
            package-lock.json
            test1/package-lock.json

      - name: Install dependencies
        working-directory: ${{ steps.workdir.outputs.dir }}
        run: npm ci

      - name: Log in to GHCR
        uses: docker/login-action@v3
        with:
          registry: ${{ env.IMAGE_REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build & Push Image
        uses: docker/build-push-action@v5
        with:
          context: ${{ steps.workdir.outputs.dir }}
          file: ${{ steps.workdir.outputs.dir }}/Dockerfile
          push: true
          platforms: linux/amd64
          tags: |
            ${{ env.IMAGE_REGISTRY }}/${{ github.repository }}:${{ steps.meta.outputs.version }}
            ${{ env.IMAGE_REGISTRY }}/${{ github.repository }}:latest
          cache-from: type=gha
          cache-to: type=gha,mode=max

  deploy:
    name: Deploy to EC2
    needs: build-test-pushh
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'
    environment: production
    steps:
      - name: Checkout (for scripts if needed)
        uses: actions/checkout@v4

      - name: Prepare SSH key
        run: |
          echo "${{ secrets.EC2_SSH_KEY }}" > key.pem
          chmod 600 key.pem
          PORT="${{ secrets.EC2_SSH_PORT }}"
          if [ -z "$PORT" ]; then PORT=22; fi
          mkdir -p ~/.ssh
          chmod 700 ~/.ssh
          ssh-keyscan -p "$PORT" -H "${{ secrets.EC2_HOST }}" >> ~/.ssh/known_hosts

      - name: Deploy containers via SSH with docker-compose
        env:
          EC2_HOST: ${{ secrets.EC2_HOST }}
          EC2_USER: ${{ secrets.EC2_USER }}
          EC2_PORT: ${{ secrets.EC2_SSH_PORT }}
          IMAGE_REGISTRY: ${{ env.IMAGE_REGISTRY }}
          REPO: ${{ github.repository }}
          TAG: ${{ needs.build-test-push.outputs.image-tag }}
          CONTAINER_NAME: ${{ env.CONTAINER_NAME }}
          DB_CONTAINER_NAME: ${{ env.DB_CONTAINER_NAME }}
          HOST_PORT: ${{ env.HOST_PORT }}
          CONTAINER_PORT: ${{ env.CONTAINER_PORT }}
          DB_PORT: ${{ env.DB_PORT }}
          DB_HOST: ${{ secrets.DB_HOST }}
          DB_NAME: ${{ secrets.DB_NAME }}
          DB_USER: ${{ secrets.DB_USER }}
          DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
          COGNITO_USER_POOL_ID: ${{ secrets.COGNITO_USER_POOL_ID }}
          COGNITO_APP_CLIENT_ID: ${{ secrets.COGNITO_APP_CLIENT_ID }}
          COGNITO_REGION: ${{ secrets.COGNITO_REGION }}
          NODE_ENV: production
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITHUB_ACTOR: ${{ github.actor }}
        run: |
          set -e
          PORT="${EC2_PORT:-22}"
          REMOTE_IMAGE="${IMAGE_REGISTRY}/${REPO}:${TAG}"
          echo "Creating env file for remote deployment"
          {
            echo "NODE_ENV=${NODE_ENV}";
            echo "PORT=${CONTAINER_PORT}";
            echo "DB_HOST=db";
            echo "DB_NAME=${DB_NAME}";
            echo "DB_USER=${DB_USER}";
            echo "DB_PASSWORD=${DB_PASSWORD}";
            echo "COGNITO_USER_POOL_ID=${COGNITO_USER_POOL_ID}";
            echo "COGNITO_APP_CLIENT_ID=${COGNITO_APP_CLIENT_ID}";
            echo "COGNITO_REGION=${COGNITO_REGION}";
          } > app_deploy.env
          echo "Creating docker-compose override for production"
          cat > docker-compose.prod.yml <<EOF
          services:
            api:
              image: ${REMOTE_IMAGE}
          EOF
          echo "Transferring files to EC2 (${EC2_HOST})"
          scp -i key.pem -P "$PORT" app_deploy.env "$EC2_USER@$EC2_HOST:/tmp/workspace-api.env"
          scp -i key.pem -P "$PORT" docker-compose.prod.yml "$EC2_USER@$EC2_HOST:/tmp/docker-compose.prod.yml"
          scp -i key.pem -P "$PORT" docker-compose.yml "$EC2_USER@$EC2_HOST:/tmp/docker-compose.yml"
          scp -i key.pem -P "$PORT" init-db.sql "$EC2_USER@$EC2_HOST:/tmp/init-db.sql"
          echo "Executing remote deployment with docker-compose"
          ssh -i key.pem -p "$PORT" "$EC2_USER@$EC2_HOST" <<REMOTE_SCRIPT
          set -euo pipefail
          APP_DIR="/opt/workspace-api"
          REMOTE_IMAGE="${REMOTE_IMAGE}"
          CONTAINER_NAME="${CONTAINER_NAME}"
          DB_CONTAINER_NAME="${DB_CONTAINER_NAME}"
          HOST_PORT="${HOST_PORT}"
          DB_PORT="${DB_PORT}"
          GITHUB_TOKEN="${GITHUB_TOKEN}"
          GITHUB_ACTOR="${GITHUB_ACTOR}"
          echo "[EC2] APP_DIR=\$APP_DIR"
          if [ -z "\$APP_DIR" ]; then
            echo "[EC2][ERROR] APP_DIR empty" >&2
            exit 11
          fi
          sudo mkdir -p "\$APP_DIR"
          if [ ! -s /tmp/workspace-api.env ]; then
            echo "[EC2][WARN] /tmp/workspace-api.env missing or empty" >&2
          fi
          sudo mv /tmp/workspace-api.env "\$APP_DIR/.env" || true
          sudo mv /tmp/docker-compose.yml "\$APP_DIR/" || true
          sudo mv /tmp/docker-compose.prod.yml "\$APP_DIR/" || true
          sudo mv /tmp/init-db.sql "\$APP_DIR/" || true
          sudo chown -R ec2-user:ec2-user "\$APP_DIR" || true
          cd "\$APP_DIR"
          echo "[EC2] Loading environment variables"
          export \$(grep -v '^#' .env | xargs)
          echo "[EC2] Docker login"
          echo "\$GITHUB_TOKEN" | docker login ghcr.io -u "\$GITHUB_ACTOR" --password-stdin || true
          echo "[EC2] Pulling \$REMOTE_IMAGE"
          docker pull "\$REMOTE_IMAGE"
          echo "[EC2] Stopping existing containers"
          docker stop "\$CONTAINER_NAME" "\$DB_CONTAINER_NAME" 2>/dev/null || true
          docker rm "\$CONTAINER_NAME" "\$DB_CONTAINER_NAME" 2>/dev/null || true
          echo "[EC2] Creating Docker network"
          docker network create workspace-network 2>/dev/null || true
          echo "[EC2] Starting PostgreSQL database"
          docker run -d --name "\$DB_CONTAINER_NAME" \
            --network workspace-network \
            --restart unless-stopped \
            -e POSTGRES_DB="\$DB_NAME" \
            -e POSTGRES_USER="\$DB_USER" \
            -e POSTGRES_PASSWORD="\$DB_PASSWORD" \
            -e PGDATA=/var/lib/postgresql/data/pgdata \
            -v postgres_data:/var/lib/postgresql/data/pgdata \
            -v "\$APP_DIR/init-db.sql:/docker-entrypoint-initdb.d/init-db.sql:ro" \
            -p "\$DB_PORT:5432" \
            --health-cmd="pg_isready -U \$DB_USER -d \$DB_NAME" \
            --health-interval=10s \
            --health-timeout=5s \
            --health-retries=5 \
            postgres:15-alpine
          echo "[EC2] Waiting for database to be healthy"
          for i in {1..30}; do
            if docker exec "\$DB_CONTAINER_NAME" pg_isready -U "\$DB_USER" -d "\$DB_NAME" >/dev/null 2>&1; then
              echo "Database is ready"; break
            fi
            echo "Waiting for database... (\$i/30)"
            sleep 2
          done
          echo "[EC2] Starting API container"
          docker run -d --name "\$CONTAINER_NAME" \
            --network workspace-network \
            --env-file "\$APP_DIR/.env" \
            -e DB_HOST="\$DB_CONTAINER_NAME" \
            -p "\$HOST_PORT:3000" \
            --restart unless-stopped \
            "\$REMOTE_IMAGE"
          docker image prune -f --filter until=168h || true
          echo "[EC2] Deployment complete"
          REMOTE_SCRIPT

      - name: Summary
        run: |
          echo "Deployed image ghcr.io/${{ github.repository }}:${{ needs.build-test-push.outputs.image-tag }} to ${{ secrets.EC2_HOST }}:${{ env.HOST_PORT }}" >> $GITHUB_STEP_SUMMARY
